{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will apply what you've learned in the past two exercises to preprocess the News Headlines Dataset for Sarcasm Detection. This contains news headlines which are labeled as sarcastic or not. You will revisit this dataset in later labs so it is good to be acquainted with it now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "# import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-26 18:49:24--  https://storage.googleapis.com/tensorflow-1-public/course3/sarcasm.json\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2607:f8b0:4009:809::201b, 2607:f8b0:4009:80a::201b, 2607:f8b0:4009:804::201b, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2607:f8b0:4009:809::201b|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5643545 (5.4M) [application/json]\n",
      "Saving to: ‘sarcasm.json’\n",
      "\n",
      "sarcasm.json        100%[===================>]   5.38M  13.7MB/s    in 0.4s    \n",
      "\n",
      "2025-07-26 18:49:24 (13.7 MB/s) - ‘sarcasm.json’ saved [5643545/5643545]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "!wget -nc https://storage.googleapis.com/tensorflow-1-public/course3/sarcasm.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sarcasm.json']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# resolve the paths\n",
    "curr_script_folder = Path.cwd()\n",
    "folders_root = curr_script_folder.parent\n",
    "root = folders_root.parent\n",
    "data_folder = root / 'data'\n",
    "\n",
    "os.listdir(data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datastore is of the type: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Load the json\n",
    "with open(data_folder / \"sarcasm.json\", 'r') as f:\n",
    "    datastore = json.load(f)\n",
    "\n",
    "print(f\"datastore is of the type: {type(datastore)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'article_link': 'https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5', 'headline': \"former versace store clerk sues over secret 'black code' for minority shoppers\", 'is_sarcastic': 0}\n",
      "\n",
      "{'article_link': 'https://www.huffingtonpost.com/entry/mh370-theft_n_5684061.html', 'headline': 'couple stole $35,000 from missing plane victims, police say', 'is_sarcastic': 0}\n"
     ]
    }
   ],
   "source": [
    "# inspect sarcastic and non sarcastic item in the datastore list\n",
    "print(datastore[0])\n",
    "print()\n",
    "print(datastore[2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sentences - headlines\n",
    "sentences = [item['headline'] for item in datastore]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the 'roseanne' revival catches up to our thorny political mood, for better and worse\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-26 19:23:45.936051: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-26 19:23:46.972156: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-07-26 19:23:48.572942: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-26 19:23:48.579325: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "# initialize the layer\n",
    "vec_layer = tf.keras.layers.TextVectorization()\n",
    "\n",
    "# build the vocab\n",
    "vec_layer.adapt(sentences)\n",
    "\n",
    "# # get vocab - optional\n",
    "# vocab = vec_layer.get_vocabulary()\n",
    "\n",
    "# post-padded sentences\n",
    "post_padded_seq = vec_layer(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: mom starting to fear son's web series closest thing she will have to grandchild\n",
      "\n",
      "post padded sequence: [  140   825     2   813  1100  2048   571  5057   199   139    39    46\n",
      "     2 13050     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0]\n",
      "\n",
      "The shape of the sequence matrix: (26709, 39)\n"
     ]
    }
   ],
   "source": [
    "index = 2\n",
    "\n",
    "print(f\"sentence: {sentences[index]}\")\n",
    "print('')\n",
    "print(f\"post padded sequence: {post_padded_seq[index]}\")\n",
    "print('')\n",
    "\n",
    "print(f\"The shape of the sequence matrix: {post_padded_seq.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets Pre-pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_layer = tf.keras.layers.TextVectorization(ragged=True)\n",
    "\n",
    "vec_layer.adapt(sentences)\n",
    "\n",
    "# get the vocab - optional\n",
    "# vocab = vec_layer.get_vocab()\n",
    "\n",
    "ragged_seq = vec_layer(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: mom starting to fear son's web series closest thing she will have to grandchild\n",
      "\n",
      "Ragged sequence: [  140   825     2   813  1100  2048   571  5057   199   139    39    46\n",
      "     2 13050]\n",
      "\n",
      "The shape of the sequence matrix: (26709, None)\n"
     ]
    }
   ],
   "source": [
    "index = 2\n",
    "\n",
    "print(f\"sentence: {sentences[index]}\")\n",
    "print('')\n",
    "print(f\"Ragged sequence: {ragged_seq[index]}\")\n",
    "print('')\n",
    "\n",
    "print(f\"The shape of the sequence matrix: {ragged_seq.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "pre_padded_seq = pad_sequences(ragged_seq.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: mom starting to fear son's web series closest thing she will have to grandchild\n",
      "\n",
      "Pre padded sequence: [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0   140   825     2   813  1100  2048   571  5057   199   139    39\n",
      "    46     2 13050]\n",
      "\n",
      "The shape of the sequence matrix: (26709, 39)\n"
     ]
    }
   ],
   "source": [
    "index = 2\n",
    "\n",
    "print(f\"sentence: {sentences[index]}\")\n",
    "print('')\n",
    "print(f\"Pre padded sequence: {pre_padded_seq[index]}\")\n",
    "print('')\n",
    "\n",
    "print(f\"The shape of the sequence matrix: {pre_padded_seq.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"the 'roseanne' revival catches up to our thorny political mood, for better and worse\",\n",
       " \"mom starting to fear son's web series closest thing she will have to grandchild\",\n",
       " 'boehner just wants wife to listen, not come up with alternative debt-reduction ideas']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "def yield_token(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield tokenizer(sentence)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_token(sentences), specials=['<pad>', '<unk>'])\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "# # get vocab - optional\n",
    "# vocab.get_itos()\n",
    "# vocab.get_stoi()\n",
    "\n",
    "# Numericalized\n",
    "seq_torch = []\n",
    "for sentence in sentences:\n",
    "    tokens = tokenizer(sentence)\n",
    "    seq = vocab(tokens)\n",
    "    seq_torch.append(torch.Tensor(seq))\n",
    "\n",
    "# seq_torch\n",
    "\n",
    "# Padding\n",
    "post_padded_seq = pad_sequence(seq_torch, batch_first=True, padding_value=vocab['<pad>'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: mom starting to fear son's web series closest thing she will have to grandchild\n",
      "\n",
      "post padded seqeuence: tensor([1.2500e+02, 8.5200e+02, 3.0000e+00, 8.1900e+02, 2.4400e+02, 2.0000e+00,\n",
      "        6.0000e+00, 2.1500e+03, 5.8900e+02, 4.6910e+03, 2.1400e+02, 9.2000e+01,\n",
      "        4.5000e+01, 5.3000e+01, 3.0000e+00, 1.2029e+04, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00])\n",
      "\n",
      "Shape of the padded matrix sequence: torch.Size([26709, 60])\n"
     ]
    }
   ],
   "source": [
    "index = 2\n",
    "\n",
    "print(f\"sentence: {sentences[index]}\")\n",
    "print()\n",
    "print(f\"post padded seqeuence: {post_padded_seq[index]}\")\n",
    "print()\n",
    "print(f\"Shape of the padded matrix sequence: {post_padded_seq.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Pre-Padding or/and Truncation use custom made functions as described in the notebook - sequences_basics.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp2llm_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
